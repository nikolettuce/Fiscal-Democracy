{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Parsing (Summaries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standard imports, add as needed\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "from random import sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gets file directory list, removes all duplicates in directory\n",
    "filedir = os.listdir('Data')\n",
    "filedir = [file for file in filedir if (\n",
    "    ('(1)' and 'copy' not in file) and (file[-3:] == 'txt'))\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pattern matching all the for arguments\n",
    "pattern_sum = r'(?i)(?=\\b(Measure|Impartial|Analysis|Counsel|Auditor)\\b).*?(?=\\b(Counsel|Analysis)\\b)\\w*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make first pass through the data, and extract the summaries\n",
    "\n",
    "Process:\n",
    "- For each file in filedir, match the line after the Impartial Analysis heading\n",
    "- Then take the next 500 \"words\" and then end the string\n",
    "- Store for analysis, and continue iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function for re-usability in next portions of project\n",
    "def match_maker(fdir, pattern):\n",
    "    match = []\n",
    "\n",
    "    for f in fdir:\n",
    "        # read file\n",
    "        fp = os.path.join('Data', f)\n",
    "        file = open(fp, 'r')\n",
    "        f_text = file.read()\n",
    "\n",
    "        # use regex to match the first instance of regex, then read the next 500 words.\n",
    "        regex_match = re.search(pattern, f_text)\n",
    "\n",
    "        # if regex matched\n",
    "        if regex_match:\n",
    "            f_text = f_text[regex_match.end():]\n",
    "            # cleaning text\n",
    "            for char in ['-','\\n']:\n",
    "                f_text = f_text.replace(char,' ')\n",
    "\n",
    "            f_split = f_text.split()\n",
    "            # debugger, ignore : print(f + \" is this long: \" + str(len(f_split)))\n",
    "            # Some matches won't have 500 characters following\n",
    "            if len(f_split) <= 500:\n",
    "                f_processed = \" \".join(f_split[:(len(f_split) - 1)])\n",
    "            else:\n",
    "                f_processed = \" \".join(f_split[:500])\n",
    "\n",
    "            # add to list\n",
    "            match.append((f, f_processed))\n",
    "        else:\n",
    "            match.append((f, 'NO MATCH'))\n",
    "        file.close()\n",
    "        \n",
    "    return match"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this function to match all of the Impartial Analyses!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We matched 79.10787437414656% of the Impartial Analyses!\n"
     ]
    }
   ],
   "source": [
    "# use pattern for summary defined previously\n",
    "match_sum = match_maker(filedir, pattern_sum)\n",
    "\n",
    "pct_matched = len([i for i in match_sum if i[1] != 'NO MATCH'])/len(match_sum)\n",
    "print('We matched ' + str(pct_matched*100) + \"% of the Impartial Analyses!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### But the Arguments are a bit harder....\n",
    "\n",
    "Plan of Action:\n",
    "- Let's filter out the file types that are a majority argumentless\n",
    "- Design a pattern to match most of the arguments for\n",
    "- Match arguments for\n",
    "- Compare to master list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2197, 1218)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# filter our sample ballot files\n",
    "filter_list = [\"SampleBallot\", \"Res.\", \"BQ\", 'bq', \"Bq\", \"Ord\", \"BallotQ\"]\n",
    "\n",
    "# define to use as a filter for other parts of project\n",
    "def list_filter(fdir, fil):\n",
    "    return [f for f in fdir if any(l for l in fil if l in f) == False]        \n",
    "        \n",
    "filedir_args = list_filter(filedir, filter_list)\n",
    "\n",
    "len(filedir), len(filedir_args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like it worked! Now lets match them :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We matched 88.17733990147784% of the docs!\n"
     ]
    }
   ],
   "source": [
    "pattern_for = r'(?i)((?!.*?(REBUTTAL).*?)(?=.*\\b(ARGUMENT))(?=.*(FAVOR|FOR)).*)'\n",
    "match_for = match_maker(filedir_args, pattern_for)\n",
    "\n",
    "total_for = len([i for i in match_for if i[1] != 'NO MATCH'])\n",
    "pct_matched_for = total_for/len(match_for)\n",
    "print('We matched ' + str(pct_matched_for * 100) + \"% of the docs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1966, 1074)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's compare our results with the master list\n",
    "master_df = pd.read_csv('MasterList2019Nov14.csv')\n",
    "# Fill all NaNs with 0, and replace 5's (Never Existed) with 0's.\n",
    "df_for = master_df.For_Coll.fillna(0).replace(5, 0)\n",
    "df_for.value_counts().loc[0], total_for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, we matched about 50% of the For arguments according to the master list, but about 88% of the For arguments from\n",
    "our filtered list. \n",
    "\n",
    "When we use the entire file directory, we get about 75% matches on that. It is still uncertain whether one with a higher likelihood\n",
    "to have false positives is better than a smaller, higher accuracy and higher precision data set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We matched 74.55621301775149% of the docs!\n"
     ]
    }
   ],
   "source": [
    "helpme= match_maker(filedir, pattern_for)\n",
    "helpme_for = len([i for i in helpme if i[1] != 'NO MATCH'])\n",
    "helpme_matched_for = helpme_for/len(helpme)\n",
    "print('We matched ' + str(helpme_matched_for * 100) + \"% of the docs!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'matchmaker' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-91c5dc70b95f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpattern_against\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mr'(?i)((?!.*?(REBUTTAL).*?)(?=.*\\b(ARGUMENT))(?=.*(AGAINST|OPPOSING)).*)'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmatch_against\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmatchmaker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiledir_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern_against\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'matchmaker' is not defined"
     ]
    }
   ],
   "source": [
    "pattern_against = r'(?i)((?!.*?(REBUTTAL).*?)(?=.*\\b(ARGUMENT))(?=.*(AGAINST|OPPOSING)).*)'\n",
    "\n",
    "match_against = matchmaker(filedir_args, pattern_against)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We matched 79.60159362549801% of the docs!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pct_matched = len([i for i in match_against if i[1] != 'NO MATCH'])/len(match_against)\n",
    "print('We matched ' + str(pct_matched*100) + \"% of the docs!\")\n",
    "len([i for i in match_against if i[1] != 'NO MATCH'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
